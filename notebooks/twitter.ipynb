{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitterスクレピング\n",
    "\n",
    "まずはログイン処理を行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from twitter.scraper import Scraper\n",
    "\n",
    "# cookies.pkl path ./../tmp/cookies.pkl to absolute path\n",
    "cookies_path = os.path.join(os.path.dirname(\"__file__\"), '..', 'tmp', 'cookies.json')\n",
    "\n",
    "# load cookies if exist\n",
    "cookies = None\n",
    "try:\n",
    "    with open(cookies_path, 'r') as f:\n",
    "        cookies = json.load(f)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if cookies:\n",
    "    scraper = Scraper(cookies=cookies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automation import ThrottleSearch\n",
    "\n",
    "search = ThrottleSearch(cookies=cookies)\n",
    "# 15分で50×20件のリクエストが上限\n",
    "res = search.run(limit=200, retries=3, queries=[\n",
    "  {'category': 'Latest', 'query': 'フリーランス min_faves:1000 lang:ja'},\n",
    "  {'category': 'Latest', 'query': 'エンジニア min_faves:1000 lang:ja'},\n",
    "  {'category': 'Latest', 'query': 'filter:follows min_faves:1000 lang:ja'},\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "\n",
    "for query_result in res:\n",
    "    for tweet in query_result:\n",
    "        result = tweet['content']['itemContent']['tweet_results']['result']\n",
    "        if result['__typename'] == 'Tweet':\n",
    "            user = result['core']['user_results']['result']\n",
    "            tweets.append({\n",
    "                # query\n",
    "                'query': tweet['query'],\n",
    "                # tweet id \n",
    "                'tweet_id': result['rest_id'],\n",
    "                # user name\n",
    "                'user_name': user['legacy']['screen_name'],\n",
    "                # user description\n",
    "                'user_description': user['legacy']['description'],\n",
    "                # follower count\n",
    "                'user_followers_count': user['legacy']['followers_count'],\n",
    "                # following count\n",
    "                'user_friends_count': user['legacy']['friends_count'],\n",
    "                'text': result['legacy']['full_text'],\n",
    "                # hashtags\n",
    "                'hashtags': [hashtag['text'] for hashtag in result['legacy']['entities']['hashtags']],\n",
    "                # posted date\n",
    "                'created_at': result['legacy']['created_at'],\n",
    "                # favorite count\n",
    "                'favorite_count': result['legacy']['favorite_count'],\n",
    "                # retweet count\n",
    "                'retweet_count': result['legacy']['retweet_count'],\n",
    "                # reply count\n",
    "                'reply_count': result['legacy']['reply_count'],\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump tweets to csv\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(tweets)\n",
    "\n",
    "output_path = os.path.join(os.path.dirname(\"__file__\"), '..', 'tweets.csv')\n",
    "\n",
    "df.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
